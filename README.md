# Backend - MLOps Pipeline con Apache Airflow


## üìã Descripci√≥n del Proyecto

Este repositorio contiene el backend, un sistema MLOps construido con Apache Airflow para la predicci√≥n de deserci√≥n estudiantil. El proyecto implementa un pipeline automatizado de machine learning que incluye:

- **Orquestaci√≥n de workflows** con Apache Airflow
- **Pipeline de limpieza de datos** automatizado
- **Entrenamiento y predicci√≥n** de modelos ML
- **CI/CD automatizado** con GitHub Actions
- **Despliegue GitOps** en Kubernetes

## üöÄ Caracter√≠sticas Principales

- ‚úÖ Pipeline ETL automatizado para datos acad√©micos
- ‚úÖ Manejo inteligente de valores faltantes y outliers
- ‚úÖ Creaci√≥n autom√°tica de caracter√≠sticas derivadas
- ‚úÖ Integraci√≥n con bases de datos MySQL
- ‚úÖ Reportes autom√°ticos de calidad de datos
- ‚úÖ Despliegue containerizado con Docker
- ‚úÖ CI/CD con GitHub Actions y GitOps

## üèóÔ∏è Estructura del Proyecto

```
egi-backend/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ ci-cd.yaml          # Pipeline CI/CD automatizado
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ mlops_dag.py           # DAG principal del pipeline MLOps
‚îÇ   ‚îî‚îÄ‚îÄ group_cleaning.py      # Grupos de tareas para limpieza
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ processing.py      # Utilidades de procesamiento de datos
‚îú‚îÄ‚îÄ volumes/
‚îÇ   ‚îî‚îÄ‚îÄ airflow/               # Datos persistentes de Airflow
‚îú‚îÄ‚îÄ docker-compose.yml         # Configuraci√≥n de servicios locales
‚îú‚îÄ‚îÄ Dockerfile                 # Imagen Docker optimizada
‚îú‚îÄ‚îÄ requirements.txt           # Dependencias Python
‚îú‚îÄ‚îÄ .gitignore                # Archivos ignorados por Git
‚îî‚îÄ‚îÄ README.md                 
```

## üì¶ Dependencias

### Dependencias Python Principales

```python
# Orquestaci√≥n
apache-airflow==2.9.2

# Machine Learning
scikit-learn
pandas
numpy
joblib

# Visualizaci√≥n
matplotlib
seaborn

# Conectividad
apache-airflow-providers-http
apache-airflow-providers-mysql
PyMySQL

# Utilidades
requests
```

### Dependencias del Sistema

- **Docker** >= 20.10
- **Docker Compose** >= 2.0
- **Python** 3.9
- **MySQL** 8.0

## ‚öôÔ∏è Configuraci√≥n del Entorno

### 1. Configuraci√≥n Local con Docker Compose

```bash
# Clonar el repositorio
git clone https://github.com/Ml-For-Academic-Data/egi-backend.git
cd egi-backend

# Crear estructura de directorios
mkdir -p volumes/airflow
mkdir -p volumes/mysql_data

# Iniciar servicios
docker-compose up -d
```

### 2. Estructura de Datos

El pipeline espera los datos en la siguiente ubicaci√≥n:
```
/opt/airflow/data/repo-datos/data/raw/dataset.csv
```

Los datos procesados se guardan en:
```
/opt/airflow/data/processed/
/opt/airflow/data/temp/
```

## üöÄ C√≥mo usar el sistema

### 1. Acceso a la Interfaz Web

Despu√©s de ejecutar `docker-compose up -d`:

- **URL**: http://localhost:8080
- **Usuario**: admin
- **Contrase√±a**: admin

### 2. Ejecutar el Pipeline MLOps

1. En la interfaz de Airflow, busca el DAG `mlops_dropout_prediction`
2. Activa el DAG usando el toggle
3. Ejecuta manualmente con "trigger DAG" o espera la ejecuci√≥n programada

### 3. Monitoreo del Pipeline

El DAG incluye las siguientes tareas:

```mermaid
graph TD
    A[start] --> B[load_data]
    B --> C[handle_missing_values]
    C --> D[remove_duplicates]
    C --> E[filter_outliers]
    D --> F[create_features]
    E --> F
    F --> G[generate_report]
    G --> H[end]
```

### 4. Revisar Resultados

Los resultados se encuentran en:
- **Datos limpios**: `/opt/airflow/data/processed/cleaned_data.csv`
- **Reporte**: `/opt/airflow/data/processed/cleaning_report.txt`

## üèóÔ∏è Despliegue

### Despliegue Local (Desarrollo)

```bash
# Iniciar todos los servicios
docker-compose up -d

# Ver logs
docker-compose logs -f airflow

# Detener servicios
docker-compose down
```

### Despliegue en Producci√≥n (Kubernetes)

El proyecto incluye un pipeline CI/CD automatizado que:

1. **Ejecuta pruebas** autom√°ticas con cada push
2. **Construye imagen Docker** y la publica en GHCR
3. **Actualiza autom√°ticamente** los manifiestos de Kubernetes

#### Configuraci√≥n Requerida

Para el despliegue automatizado, configura estos secrets en GitHub:

```bash
# Token para acceder al repositorio de infraestructura
REPO_ACCESS_TOKEN
```

#### Pipeline de Despliegue

```yaml
# El pipeline se activa autom√°ticamente en:
- Push a rama main
- Pull requests a main

# Flujo:
Test ‚Üí Build Image ‚Üí Update K8s Manifests ‚Üí Deploy
```

## üß™ Desarrollo

### Ejecutar Pruebas Localmente

```bash
# Instalar dependencias de desarrollo
pip install -r requirements.txt
pip install flake8 pytest

# Ejecutar linting
flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
```

### Estructura de Desarrollo

```python
# Para agregar nuevas funciones de procesamiento
# Editar: src/utils/processing.py

# Para modificar el pipeline principal
# Editar: dags/mlops_dag.py

# Para cambiar la configuraci√≥n de servicios
# Editar: docker-compose.yml
```

### Mejores Pr√°cticas

1. **Commits**: Usa conventional commits (`feat:`, `fix:`, `docs:`)
2. **Branching**: Crea feature branches desde `main`
3. **Testing**: Agrega pruebas para nuevas funcionalidades
4. **Documentation**: Actualiza la documentaci√≥n con cambios importantes

## üîß Configuraci√≥n Avanzada

### Personalizar el Ejecutor de Airflow

Para producci√≥n, cambia el ejecutor en `docker-compose.yml`:

```yaml
# Para mayor paralelismo
AIRFLOW__CORE__EXECUTOR=LocalExecutor
# o
AIRFLOW__CORE__EXECUTOR=CeleryExecutor
```

### Configurar Conexiones de Base de Datos

En la interfaz de Airflow:
1. Ve a **Admin** ‚Üí **Connections**
2. Crea nueva conexi√≥n MySQL:
   - **Connection Id**: `mysql_default`
   - **Connection Type**: `MySQL`
   - **Host**: `mysql-server`
   - **Login**: `user`
   - **Password**: `1234`
   - **Schema**: `students`

## üìä Monitoreo y Logs

### Ver Logs de Contenedores

```bash
# Logs de Airflow Webserver
docker logs airflow

# Logs de Airflow Scheduler
docker logs airflow-scheduler

# Logs de MySQL
docker logs mysql-server
```

### M√©tricas del Pipeline

El DAG genera autom√°ticamente m√©tricas incluyendo:
- N√∫mero de filas procesadas
- Valores faltantes manejados
- Outliers removidos
- Features creadas

**Hecho por el equipo Byte Builders**
